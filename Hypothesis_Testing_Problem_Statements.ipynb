{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarshaPriya03/PythonLearning/blob/main/Hypothesis_Testing_Problem_Statements.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Steps for Performing a Hypothesis Test**\n",
        "\n",
        "1. **State the Hypotheses**\n",
        "  -  **Null Hypothesis($H_0$)**: The default assumption or claim to be tested (e.g., \"There is no difference in means\").\n",
        "\n",
        "  - **Alternative Hypothesis($H_1$)**: The claim you want to test for (e.g., \"There is a difference in means\").\n",
        "\n",
        "2. **Choose the Significance Level (α)**\n",
        "  - Common choices are 0.05, 0.01, or 0.10.\n",
        "\n",
        "  - This is the threshold for deciding whether a result is statistically significant.\n",
        "\n",
        "3. **Select the Appropriate Test**\n",
        "\n",
        "  - Decide which statistical test suits your data and hypothesis (e.g., t-test, z-test, chi-square test, ANOVA).\n",
        "\n",
        "4. **Calculate the Test Statistic**\n",
        "  - Use the sample data to compute the test statistic (e.g., t, z, F, or chi-square value) based on the chosen test.\n",
        "\n",
        "5. **Compute the p-value**\n",
        "  - The p-value is the probability of observing a test statistic as extreme as, or more extreme than, the one calculated(assuming the null hypothesis is true).\n",
        "\n",
        "6. **Compare the p-value to the Significance Level**\n",
        "  - **If p-value ≤ α**: Reject the null hypothesis($H_0$). There is sufficient evidence to support the alternative hypothesis.\n",
        "\n",
        "  - **If p-value > α** : Fail to reject the null hypothesis($H_0$). There is insufficient evidence to support the alternative hypothesis.\n",
        "\n",
        "7. **State the Conclusion**\n",
        "  - Clearly state the result in the context of the problem, referencing whether the null hypothesis was rejected or not."
      ],
      "metadata": {
        "id": "o3IVP-bV0_37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "kkAqssXyKhCm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **The Significance Level**\n",
        "\n",
        "Imagine you’re a doctor testing a new medicine. You want to know if it really works better than the old one. To decide, you run an experiment with patients and collect data.\n",
        "\n",
        "**The Courtroom Analogy** : Think of your experiment like a courtroom trial:\n",
        "\n",
        "- Null Hypothesis ($H_0$): The new medicine is no better than the old one (the defendant is innocent).\n",
        "\n",
        "- Alternative Hypothesis ($H_1$): The new medicine is better (the defendant is guilty).\n",
        "\n",
        "In court, you don’t want to wrongly convict an innocent person. In science, you don’t want to wrongly claim your medicine works when it doesn’t. This mistake is called a **Type I error**.\n",
        "\n",
        "**Enter the Significance Level ($\\alpha$)**\n",
        "\n",
        "The significance level, often written as $\\alpha$, is like the judge setting a threshold for evidence. It’s the maximum probability you’re willing to accept for making a Type I error—declaring the medicine works when it actually doesn’t.\n",
        "\n",
        "If you set $\\alpha = 0.05$, you’re saying: “I’m willing to accept a 5% chance of being wrong if I claim the new medicine is better.”"
      ],
      "metadata": {
        "id": "ird8DSMuJ1CJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **p-value**\n",
        "\n",
        "- The higher the p_value, the lower the chances of rejecting the Null Hypothesis.\n",
        "- The lower the p_value, the higher are the chances of rejecting the Null Hypothesis."
      ],
      "metadata": {
        "id": "QfBGM1s-a4sA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "TDZoDPpJKjLT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Z-Test**\n",
        "\n",
        "A z-test is a statistical method used in hypothesis testing to determine if there is a significant difference between sample and population means, or between the means of two samples. It is particularly useful when the population standard deviation is known and the sample size is large (typically greater than 30).\n",
        "\n",
        "`We have mainly two types of z-test:`\n",
        "\n",
        "1. **One-Sample Z-Test:** Used to determine whether the mean of a single sample is different from a known population mean.\n",
        "2. **Two-Sample Z-Test:** Used to compare the means of two independent samples to see if they are significantly different from each other.\n",
        "\n",
        "**Assumptions of Z-Tests**\n",
        "\n",
        "For a z-test to yield valid/correct results, these assumptions must be met:\n",
        "1. **Normal Distribution:** The data should be approximately normally distributed. This assumption is satisfied with large sample sizes due to the central limit theorem.\n",
        "2. **Known Population Standard Deviation:** The standard deviation of the population must be known. If it is unknown, using a `t-test` is more appropriate.\n",
        "3. **Random Sampling:** The sample data should be randomly drawn from the population, ensuring that it is representative of the actual population data.\n",
        "4. **Independence:** The samples must be independent of each other, particularly in two-sample z-tests.\n",
        "5. **Continuous Data:** The z-test is applicable for continuous data, where the variable of interest can take any numeric value."
      ],
      "metadata": {
        "id": "xk41qkUk4W-N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "UCXHhv7oKlU9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1. One-Sample Z-test (One sample test for known pop variance)**\n",
        "\n",
        "**Scenario 1: Manufacturing Quality Control**\n",
        "\n",
        "A pharmaceutical company produces a specific tablet that must contain exactly 500 mg of an active ingredient. Historical data from their high-precision machines indicates a population standard deviation ($\\sigma$) of 10 mg. A Quality Assurance (QA) engineer randomly samples 50 batches and finds the average content is 496 mg. They need to determine if the machine has drifted out of calibration.\n",
        "\n",
        "**Null Hypothesis ($H_0$):** The machine is calibrated correctly. The mean content is equal to the target.$$H_0: \\mu = 500$$\n",
        "\n",
        "**Alternative Hypothesis ($H_1$):** The machine is out of calibration. The mean content is not equal to the target.$$H_1: \\mu \\neq 500$$"
      ],
      "metadata": {
        "id": "JrNCmWqqFr5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Given Data\n",
        "population_mean = 500\n",
        "population_std = 10\n",
        "sample_size = 50\n",
        "sample_mean = 496\n",
        "\n",
        "# Calculate Z-Score\n",
        "# Formula: (sample_mean - pop_mean) / (pop_std / sqrt(n))\n",
        "z_statistic = (sample_mean - population_mean) / (population_std / np.sqrt(sample_size))\n",
        "\n",
        "# Calculate P-Value (Two-tailed test)\n",
        "p_value = stats.norm.sf(abs(z_statistic)) * 2\n",
        "\n",
        "print(f\"Z-Score: {z_statistic:.4f}\")\n",
        "print(f\"P-Value: {p_value:.4f}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject Null Hypothesis: The machine has drifted out of calibration.\")\n",
        "else:\n",
        "    print(\"Fail to Reject Null: The deviation is likely due to chance.\")"
      ],
      "metadata": {
        "id": "pchTSOv5GTBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "mXLw1-gsaOGr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario: Quality Assurance (Food Manufacturing)**\n",
        "\n",
        "**Problem Statement:** A large food processing plant produces \"Energy Bars\" that are advertised to weigh exactly 50 grams. The strict quality control policy states that the production line standard deviation is known to be 2 grams due to mechanical variances.\n",
        "\n",
        "A Quality Assurance Data Scientist randomly samples 100 bars from today's production batch and finds the average weight is 49.5 grams. They need to test if the machinery has drifted significantly from the target weight of 50g."
      ],
      "metadata": {
        "id": "pUJWH5RwQFF-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hypothesis Statements:**\n",
        "\n",
        "- **Null Hypothesis ($H_0$):** The average weight of the bars is equal to the target. (The machine is working correctly).$$H_0: \\mu = 50$$\n",
        "\n",
        "- **Alternative Hypothesis ($H_1$):** The average weight of the bars is not equal to the target. (The machine is miscalibrated).$$H_1: \\mu \\neq 50$$"
      ],
      "metadata": {
        "id": "rz26bhh9QWMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# 1. Setup Data\n",
        "pop_mean = 50\n",
        "pop_std_dev = 2\n",
        "sample_size = 100\n",
        "sample_mean = 49.5\n",
        "\n",
        "# Simulate the sample data (Mean is shifted to 49.5 to simulate a problem)\n",
        "sample_data = np.array([50.40483822, 46.8761864 , 48.88114199, 51.30141821, 49.33128064,\n",
        "       46.09371437, 50.14253783, 52.62251794, 51.48639237, 51.76837878,\n",
        "       48.68765281, 50.161313  , 48.32608142, 49.34135682, 47.9729816 ,\n",
        "       49.28430948, 51.73274552, 50.25960079, 48.7359658 , 47.13827422,\n",
        "       49.71008232, 52.70339994, 46.66162822, 53.3433419 , 52.78276636,\n",
        "       53.43381614, 49.63156066, 46.22869873, 46.73314012, 48.98528066,\n",
        "       47.50090802, 49.75194656, 51.97821175, 51.29384476, 48.98192443,\n",
        "       50.72538558, 48.00899826, 52.47304215, 49.33947076, 49.04525544,\n",
        "       49.22226128, 48.01008311, 49.25012366, 46.82159139, 49.99530902,\n",
        "       47.71889532, 49.68001116, 48.09053674, 48.82212249, 46.63723591,\n",
        "       49.14591185, 47.97374877, 46.49607605, 50.50171503, 48.0091587 ,\n",
        "       51.18485864, 48.94155265, 54.12698446, 50.75096089, 54.31920821,\n",
        "       46.54053288, 48.53904457, 49.61707527, 48.66808338, 50.55790802,\n",
        "       50.10122835, 47.79250497, 50.45203966, 51.7998047 , 47.50426235,\n",
        "       47.84189047, 49.02526641, 48.2429361 , 49.19689951, 51.54477141,\n",
        "       49.88651678, 50.97091732, 49.42268857, 49.63775632, 49.81267013,\n",
        "       49.54469218, 49.17206591, 49.52264168, 52.81964232, 49.18501505,\n",
        "       51.04107237, 49.6800387 , 51.60434694, 49.8592259 , 49.21821781,\n",
        "       50.13179064, 49.44307184, 42.19376068, 52.79645355, 50.35153978,\n",
        "       48.09518794, 50.83571755, 47.71391235, 50.35067636, 53.36916694])\n",
        "\n",
        "# 2. Perform One-Sample Z-Test\n",
        "# 'value' is the mean under the Null Hypothesis\n",
        "#z_stat, p_value = ztest(sample_data, value=population_mean_target)\n",
        "\n",
        "z_stat = (sample_mean - pop_mean) / (pop_std_dev / (np.sqrt(sample_size)))\n",
        "\n",
        "p_val = stats.norm.cdf(z_stat)\n",
        "\n",
        "# 3. Interpret Results\n",
        "alpha = 0.05\n",
        "print(f\"Z-Statistic: {z_stat:.4f}\")\n",
        "print(f\"P-Value: {p_val:.4f}\")\n",
        "\n",
        "if p_val < alpha:\n",
        "    print(\"Reject Null Hypothesis: The machinery is miscalibrated (Significant difference).\")\n",
        "else:\n",
        "    print(\"Fail to Reject Null Hypothesis: The production is within acceptable limits.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4JArdRiQvs0",
        "outputId": "d83809a2-f205-4baa-c193-75b75bd62e24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Z-Statistic: -2.5000\n",
            "P-Value: 0.0062\n",
            "Reject Null Hypothesis: The machinery is miscalibrated (Significant difference).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Y0kISV7caQw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**:\n",
        "\n",
        "- When we have ≠ in Alternate Hypothesis then we reject the null hypothesis if p_value * 2 < 5%.\n",
        "\n",
        "- And if we have < or > symbols in alternate hypothesis then we reject the null hypothesis if p_value < 5%."
      ],
      "metadata": {
        "id": "ABY0BpLiEwGG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "2X0PncR4Km_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Two Sample Z-test**"
      ],
      "metadata": {
        "id": "d-gMyTdTa3o3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario 1: E-Commerce A/B Testing (Average Order Value)**\n",
        "\n",
        "A large online fashion retailer, \"StyleHub,\" is testing a new checkout page design (Design B) against their current design (Design A). They believe the new design streamlines the process and encourages users to add more small accessories before paying. They have collected data from 200 randomly selected users for each design. The Data Science team needs to determine if there is a statistically significant difference in the Average Order Value (AOV) between the two designs."
      ],
      "metadata": {
        "id": "NBEoqlkHa-Fd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hypothesis Statements:\n",
        "\n",
        "Let $\\mu_A$ be the mean AOV of Design A and $\\mu_B$ be the mean AOV of Design B.\n",
        "\n",
        "- **Null Hypothesis ($H_0$)**: There is no difference in the Average Order Value between the two designs.$$H_0: \\mu_A - \\mu_B = 0$$\n",
        "\n",
        "- **Alternative Hypothesis ($H_1$)**: There is a significant difference in the Average Order Value between the two designs.$$H_1: \\mu_A - \\mu_B \\neq 0$$"
      ],
      "metadata": {
        "id": "c-ur0az7bHV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from statsmodels.stats.weightstats import ztest\n",
        "\n",
        "# 1. Simulate Data (Large sample size > 30 implies Z-test is applicable)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Design A: Mean $120, Std Dev $15, N=200\n",
        "design_a_aov = np.random.normal(loc=120, scale=15, size=200)\n",
        "\n",
        "# Design B: Mean $125, Std Dev $18, N=200\n",
        "design_b_aov = np.random.normal(loc=125, scale=18, size=200)\n",
        "\n",
        "# 2. Perform Two-Sample Z-Test\n",
        "# value=0 implies we are testing for a difference of 0\n",
        "z_stat, p_value = ztest(design_a_aov, design_b_aov, value=0)\n",
        "\n",
        "# 3. Interpret Results\n",
        "alpha = 0.05\n",
        "print(f\"Z-Statistic: {z_stat:.4f}\")\n",
        "print(f\"P-Value: {p_value:.4f}\")\n",
        "\n",
        "if p_value < alpha:\n",
        "    print(\"Reject Null Hypothesis: There is a significant difference in AOV between designs.\")\n",
        "else:\n",
        "    print(\"Fail to Reject Null Hypothesis: No significant difference found.\")"
      ],
      "metadata": {
        "id": "a4bfcSJzbGa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "fqjLaMtaKoe5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **T-test**"
      ],
      "metadata": {
        "id": "KoSX1gd66V-Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1. One-Sample t-test (One Sample test for unknown pop variance)**\n",
        "\n",
        "**Business Problem Statement**\n",
        "\n",
        "A beverage company claims that the average content of its soda cans is 330 ml. The quality control team wants to verify this claim by measuring the content of a random sample of cans.\n",
        "\n",
        "**Hypotheses**\n",
        "  - **Null hypothesis ($H_0$)**: The mean content in soda cans is 330 ml ($\\mu = 330$).\n",
        "\n",
        "  - **Alternative hypothesis ($H_1$)**: The mean content is not 330 ml ($\\mu \\neq 330$)."
      ],
      "metadata": {
        "id": "lIxeBF1t6uRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import ttest_1samp\n",
        "from scipy.stats import shapiro\n",
        "\n",
        "#sample data of 15 cans\n",
        "sample_data = np.array([332, 329, 331, 328, 334, 330, 327, 333, 329, 331, 332, 328, 330, 334, 329])\n",
        "\n",
        "#shapiro-wilk for normality of the sample\n",
        "shapiro_stat, shapiro_p_value = shapiro(sample_data)\n",
        "print(shapiro_p_value)\n",
        "\n",
        "# 1-sample t-test on the data\n",
        "t_statistic, p_value = ttest_1samp(sample_data, popmean = 330)\n",
        "print(p_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kF7Wh_V48xOu",
        "outputId": "a23eedc2-03e2-4f62-a251-20133f6e4314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5372052570493318\n",
            "0.4250186718429414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import ttest_1samp\n",
        "from scipy.stats import shapiro\n",
        "\n",
        "#sample data of 15 cans\n",
        "sample_data = np.array([332, 329, 331, 328, 334, 330, 327, 333, 329, 331, 332, 328, 330, 334, 329])\n",
        "\n",
        "shapiro_stat, p_value_shapiro = shapiro(sample_data)\n",
        "print(p_value_shapiro)\n",
        "\n",
        "#perform the t-test using ttest-1samp function\n",
        "t_statistic, p_value = ttest_1samp(sample_data, popmean = 330, alternative = 'two-sided')\n",
        "\n",
        "print(p_value)"
      ],
      "metadata": {
        "id": "w5IRRwDNiEcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: If the sample data is not normally distributed, then we can run **Wilcoxon-Signed Rank test** as an alternative of 1 sample t-test."
      ],
      "metadata": {
        "id": "DKToWtNHK8dg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "zVSatLvtKqB4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2. Two Sample t-test**\n",
        "\n",
        "**Business Problem Statement**\n",
        "\n",
        "An HR department wants to compare the average monthly salaries of employees in two different departments (A and B) to determine if there is a significant difference.\n",
        "\n",
        "**Hypotheses**\n",
        "\n",
        " - Null hypothesis ($H_0$): The mean salary in Department A equals that in Department B ($\\mu_1 = \\mu_2$).\n",
        "\n",
        " - Alternative hypothesis ($H_1$): The mean salaries are different ($\\mu_1 \\neq \\mu_2$)."
      ],
      "metadata": {
        "id": "UU58lyfi7uUm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before performing a two-sample t-test, it is important to check two key assumptions:\n",
        "\n",
        "- Normality: Each sample should be approximately normally distributed.\n",
        "\n",
        "- Equality of Variances: The two samples should have similar variances (for the standard t-test)."
      ],
      "metadata": {
        "id": "DFQK7mWV8dsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import shapiro, levene, ttest_ind, mannwhitneyu\n",
        "\n",
        "# Monthly salaries in USD for two departments\n",
        "dept_a = np.array([4500, 4700, 4200, 4800, 4600, 4400, 4550, 4650, 4750, 4300])\n",
        "dept_b = np.array([4000, 4150, 4100, 3950, 4200, 4050, 4100, 4000, 4150, 4050])\n",
        "\n",
        "#shapiro-wilk test for normality of the samples\n",
        "shap_stat_a, shap_p_val_a = shapiro(dept_a)\n",
        "shap_stat_b, shap_p_val_b = shapiro(dept_b)\n",
        "print(shap_p_val_a, shap_p_val_b)\n",
        "\n",
        "#levene test to check for equality of variances\n",
        "levene_stat,levene_p_val = levene(dept_a, dept_b)\n",
        "print(levene_p_val)\n",
        "\n",
        "#two-sample independent t-test\n",
        "t_stats, p_val = ttest_ind(dept_a, dept_b, equal_var = False)\n",
        "print(p_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYuKYKOnGgHp",
        "outputId": "1b2c7c5c-a582-43e5-973f-cb4192a824d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7713665744080458 0.8485975564649946\n",
            "0.029281204462727414\n",
            "1.4988271248674483e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. The sample data**"
      ],
      "metadata": {
        "id": "2pZL5mb2_Y1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Monthly salaries in USD for two departments\n",
        "dept_a = np.array([4500, 4700, 4200, 4800, 4600, 4400, 4550, 4650, 4750, 4300])\n",
        "dept_b = np.array([4000, 4150, 4100, 3950, 4200, 4050, 4100, 4000, 4150, 4050])"
      ],
      "metadata": {
        "id": "Yyp8raen7zAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Use the Shapiro-Wilk test to check if each sample follow a normal distribution.**"
      ],
      "metadata": {
        "id": "EiZxMwGo8lwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import shapiro\n",
        "\n",
        "# Shapiro-Wilk test for normality\n",
        "stat_a, p_a = shapiro(dept_a)\n",
        "stat_b, p_b = shapiro(dept_b)\n",
        "\n",
        "print(f\"Dept A: p-value = {p_a:.4f}\")\n",
        "print(f\"Dept B: p-value = {p_b:.4f}\")\n",
        "\n",
        "if p_a > 0.05:\n",
        "    print(\"Dept A: Sample looks normal.\")\n",
        "else:\n",
        "    print(\"Dept A: Sample does NOT look normal.\")\n",
        "\n",
        "if p_b > 0.05:\n",
        "    print(\"Dept B: Sample looks normal.\")\n",
        "else:\n",
        "    print(\"Dept B: Sample does NOT look normal.\")"
      ],
      "metadata": {
        "id": "c_4cUkXw8pVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the p-value of shapiro wilk test is greater than 0.05, the sample can be considered normally distributed."
      ],
      "metadata": {
        "id": "WufOv3kN8u1Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Use Levene's test to check if the variances of the two samples are equal.**"
      ],
      "metadata": {
        "id": "EwdWiiHz_uVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import levene\n",
        "\n",
        "# Levene's test for equal variances\n",
        "stat_levene, p_levene = levene(dept_a, dept_b)\n",
        "\n",
        "print(f\"Levene's test p-value = {p_levene:.4f}\")\n",
        "\n",
        "if p_levene > 0.05:\n",
        "    print(\"Variances are equal.\")\n",
        "    equal_var = True\n",
        "else:\n",
        "    print(\"Variances are NOT equal.\")\n",
        "    equal_var = False"
      ],
      "metadata": {
        "id": "pbenGWrM8zf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the p-value of levene test is greater than 0.05, you can assume equal variances"
      ],
      "metadata": {
        "id": "0hh6V-wX9Ae5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Choose the appropriate t-test based on the result of Levene's test.**"
      ],
      "metadata": {
        "id": "ncGtU_v-9YYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Two-sample t-test (Welch's if variances unequal)\n",
        "t_stat, p_value = ttest_ind(dept_a, dept_b, equal_var=False)\n",
        "\n",
        "print(f\"T-statistic: {t_stat:.2f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")"
      ],
      "metadata": {
        "id": "nt29LiCt9BEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the p-value is less than 0.05, you can conclude there is a significant difference in means."
      ],
      "metadata": {
        "id": "xjdyi04F9d44"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario 3: R&D Battery Testing (Two-Sample Independent T-Test), Domain: Manufacturing / Hardware Engineering**\n",
        "\n",
        "A tech company is selecting a battery supplier for their new smartwatch. Supplier A claims their battery lasts 24 hours. Supplier B is cheaper but claims similar performance.\n",
        "**Constraint:** Testing is expensive and time-consuming. The engineering team can only test 12 batteries from each supplier. Since $n < 30$, a Z-test is inappropriate; we must use a T-test.\n",
        "\n",
        "Null Hypothesis ($H_0$): The average battery life of Supplier A and Supplier B is identical.$$H_0: \\mu_A = \\mu_B$$\n",
        "\n",
        "Alternative Hypothesis ($H_1$): The average battery life differs between the two suppliers.$$H_1: \\mu_A \\neq \\mu_B$$"
      ],
      "metadata": {
        "id": "saKh_JPELSvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Data (Hours of battery life)\n",
        "# Small sample sizes (n=12)\n",
        "supplier_a = [24.1, 23.8, 24.5, 23.0, 24.2, 23.9, 24.0, 23.5, 24.8, 24.1, 23.7, 24.3]\n",
        "supplier_b = [22.8, 23.1, 22.5, 23.0, 22.9, 23.5, 22.1, 23.3, 22.8, 23.0, 22.7, 23.4]\n",
        "\n",
        "# 2. Perform T-Test (Assuming equal variance for this hardware spec)\n",
        "t_stat, p_val = stats.ttest_ind(supplier_a, supplier_b, equal_var=True)\n",
        "\n",
        "print(f\"Supplier A Mean: {sum(supplier_a)/len(supplier_a):.2f} hrs\")\n",
        "print(f\"Supplier B Mean: {sum(supplier_b)/len(supplier_b):.2f} hrs\")\n",
        "print(f\"P-Value: {p_val:.6f}\") # Using 6f because p-value might be very small\n",
        "\n",
        "# 3. Decision\n",
        "if p_val < 0.05:\n",
        "    print(\"Reject Null: Supplier A performs significantly better (or different).\")\n",
        "    # Interpretation: If A > B and significant, don't buy B even if it's cheaper!\n",
        "else:\n",
        "    print(\"Fail to Reject Null: No significant difference found.\")"
      ],
      "metadata": {
        "id": "uXlSVFT_LlAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "PlzhBkMBKsZ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ANOVA**\n",
        "\n",
        "Before performing a one-way ANOVA, it is essential to check the following key assumptions:\n",
        "\n",
        "- Normality: Each group should be approximately normally distributed.\n",
        "\n",
        "- Homogeneity of Variances: All groups should have similar variances.\n",
        "\n",
        "- Independence: Observations should be independent (usually ensured by study design)."
      ],
      "metadata": {
        "id": "mBDcGIacD8oV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario 1: Marketing Campaign Effectiveness Problem**\n",
        "\n",
        "**Statement**: A digital marketing team wants to determine which social media platform yields the highest user engagement score (0-100) for a new product launch. They run simultaneous campaigns on TikTok, Instagram, and LinkedIn and collect engagement scores from random users on each platform.\n",
        "\n",
        "Hypothesis Formulation:\n",
        "- **Null Hypothesis ($H_0$)**: There is no significant difference in the mean engagement scores across the three platforms.$$H_0: \\mu_{TikTok} = \\mu_{Instagram} = \\mu_{LinkedIn}$$\n",
        "- **Alternative Hypothesis ($H_1$)**: At least one platform has a mean engagement score different from the others."
      ],
      "metadata": {
        "id": "UOhrj7-dUz2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import f_oneway, shapiro, levene, kruskal\n",
        "\n",
        "tiktok = np.array([65.70876234, 75.24148111, 53.36094   , 88.31124168, 66.9498208 ,\n",
        "       62.7274252 , 84.95705692, 73.6630608 , 74.53086367, 80.41976844,\n",
        "       61.79220387, 74.1663686 , 84.6109146 , 65.48623431, 73.93197654,\n",
        "       94.78663015, 78.69687923, 63.32408083, 63.86821659, 64.15995633,\n",
        "       79.18828803, 66.04985321, 62.63865761, 77.99304857, 83.73391146,\n",
        "       69.32029347, 55.91996341, 51.52365563, 75.99622561, 69.89560614])\n",
        "\n",
        "instagram = np.array([76.38405464, 83.48538268, 68.92500799, 77.15189002, 60.37999486,\n",
        "       54.9064827 , 84.64504956, 76.26070475, 51.35595813, 81.21324046,\n",
        "       75.16737898, 66.89979229, 76.945872  , 85.60134782, 58.56430539,\n",
        "       72.17314063, 52.95971012, 73.63052986, 63.54290254, 72.16740738,\n",
        "       79.10188442, 83.40293232, 70.20805162, 58.08966378, 80.21496265,\n",
        "       70.56094365, 70.68869961, 72.30945941, 76.05238316, 71.82903503])\n",
        "\n",
        "linkedin = np.array([74.09639092, 62.94630478, 65.10572241, 81.18655794, 63.9444842 ,\n",
        "       74.01858283, 65.93010531, 78.05168414, 57.61019555, 65.94576657,\n",
        "       73.24615889, 85.56356553, 63.36566193, 65.25667837, 62.22340595,\n",
        "       76.34393328, 77.79381458, 57.40172342, 61.51665284, 63.05031077,\n",
        "       58.25281691, 66.58920115, 73.26048231, 40.97154251, 52.80879973,\n",
        "       67.46343802, 60.08994255, 60.4971181 , 59.24497195, 80.8282937 ])"
      ],
      "metadata": {
        "id": "bAQz1dzssT-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Assumption Checks ---\")\n",
        "\n",
        "# 2. Check Assumption 1: Normality (Shapiro-Wilk Test)\n",
        "# H0: The data is normally distributed.\n",
        "# H1: The data is NOT normally distributed.\n",
        "# We fail to reject H0 if p-value > 0.05\n",
        "\n",
        "groups = {'TikTok': tiktok, 'Instagram': instagram, 'LinkedIn': linkedin}\n",
        "normality_passed = True\n",
        "\n",
        "for name, data in groups.items():\n",
        "    stat, p = shapiro(data)\n",
        "    print(f\"{name} Normality p-value: {p:.4f}\")\n",
        "    if p < 0.05:\n",
        "        normality_passed = False\n",
        "        print(f\"--> Warning: {name} data may not be normally distributed.\")\n",
        "\n",
        "if normality_passed:\n",
        "    print(\"Result: Normality assumption holds (all p > 0.05).\")\n",
        "else:\n",
        "    print(\"Result: Normality assumption violated.\")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# 3. Check Assumption 2: Homogeneity of Variance (Levene's Test)\n",
        "\n",
        "stat, p_levene = levene(tiktok, instagram, linkedin)\n",
        "print(f\"Levene's Test p-value: {p_levene:.4f}\")\n",
        "\n",
        "variance_passed = True\n",
        "if p_levene < 0.05:\n",
        "    variance_passed = False\n",
        "    print(\"Result: Homogeneity of variance assumption violated.\")\n",
        "else:\n",
        "    print(\"Result: Homogeneity of variance assumption holds.\")\n",
        "\n",
        "print(\"\\n-------------------------\")\n",
        "\n",
        "# 4. Run ANOVA (Only if assumptions are reasonably met)\n",
        "# Note: ANOVA is robust to slight deviations, but if assumptions fail badly,\n",
        "# we should use Kruskal-Wallis (Non-parametric).\n",
        "\n",
        "if normality_passed and variance_passed:\n",
        "    print(\"Assumptions met. Running One-Way ANOVA...\")\n",
        "    f_stat, p_value = f_oneway(tiktok, instagram, linkedin)\n",
        "    print(f\"F-Statistic: {f_stat:.2f}\")\n",
        "    print(f\"P-Value: {p_value:.4f}\")\n",
        "\n",
        "    if p_value < 0.05:\n",
        "        print(\"Final Conclusion: Significant difference found between platforms.\")\n",
        "    else:\n",
        "        print(\"Final Conclusion: No significant difference found.\")\n",
        "else:\n",
        "    print(\"Assumptions violated. Consider using Kruskal-Wallis H-test instead.\")"
      ],
      "metadata": {
        "id": "UrGqgIGLVAtF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49d76c50-d3dc-4ef9-d29f-f5b914fd4ea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Assumption Checks ---\n",
            "TikTok Normality p-value: 0.8886\n",
            "Instagram Normality p-value: 0.0931\n",
            "LinkedIn Normality p-value: 0.3852\n",
            "Result: Normality assumption holds (all p > 0.05).\n",
            "\n",
            "\n",
            "Levene's Test p-value: 0.6090\n",
            "Result: Homogeneity of variance assumption holds.\n",
            "\n",
            "-------------------------\n",
            "Assumptions met. Running One-Way ANOVA...\n",
            "F-Statistic: 2.56\n",
            "P-Value: 0.0829\n",
            "Final Conclusion: No significant difference found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groups"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThYu5t3ZOUb_",
        "outputId": "9daf7282-fa67-4455-c9ba-29e10a73ec74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'TikTok': array([65.70876234, 75.24148111, 53.36094   , 88.31124168, 66.9498208 ,\n",
              "        62.7274252 , 84.95705692, 73.6630608 , 74.53086367, 80.41976844,\n",
              "        61.79220387, 74.1663686 , 84.6109146 , 65.48623431, 73.93197654,\n",
              "        94.78663015, 78.69687923, 63.32408083, 63.86821659, 64.15995633,\n",
              "        79.18828803, 66.04985321, 62.63865761, 77.99304857, 83.73391146,\n",
              "        69.32029347, 55.91996341, 51.52365563, 75.99622561, 69.89560614]),\n",
              " 'Instagram': array([76.38405464, 83.48538268, 68.92500799, 77.15189002, 60.37999486,\n",
              "        54.9064827 , 84.64504956, 76.26070475, 51.35595813, 81.21324046,\n",
              "        75.16737898, 66.89979229, 76.945872  , 85.60134782, 58.56430539,\n",
              "        72.17314063, 52.95971012, 73.63052986, 63.54290254, 72.16740738,\n",
              "        79.10188442, 83.40293232, 70.20805162, 58.08966378, 80.21496265,\n",
              "        70.56094365, 70.68869961, 72.30945941, 76.05238316, 71.82903503]),\n",
              " 'LinkedIn': array([74.09639092, 62.94630478, 65.10572241, 81.18655794, 63.9444842 ,\n",
              "        74.01858283, 65.93010531, 78.05168414, 57.61019555, 65.94576657,\n",
              "        73.24615889, 85.56356553, 63.36566193, 65.25667837, 62.22340595,\n",
              "        76.34393328, 77.79381458, 57.40172342, 61.51665284, 63.05031077,\n",
              "        58.25281691, 66.58920115, 73.26048231, 40.97154251, 52.80879973,\n",
              "        67.46343802, 60.08994255, 60.4971181 , 59.24497195, 80.8282937 ])}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "4f0EK4bhKvCD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparing Customer Satisfaction Across Service Centers**\n",
        "\n",
        "**Problem Statement**\n",
        "\n",
        "An automotive company operates four service centers in different cities. The company collects customer satisfaction scores (on a scale of 1 to 10) from recent customers at each center. Management wants to determine if customer satisfaction differs significantly across the service centers.\n",
        "\n",
        "**Hypotheses**\n",
        "\n",
        "- **Null Hypothesis ($H_0$)**: The mean customer satisfaction scores are equal across all service centers ($\\mu_1 = \\mu_2 = \\mu_3 = \\mu_4$).\n",
        "\n",
        "- **Alternative Hypothesis ($H_1$)**: At least one service center has a different mean satisfaction score."
      ],
      "metadata": {
        "id": "aJkHEzBQFMYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import f_oneway, shapiro, levene, kruskal\n",
        "\n",
        "# Satisfaction scores for each service center\n",
        "center_1 = np.array([8, 9, 7, 8, 9])\n",
        "center_2 = np.array([6, 7, 6, 8, 7])\n",
        "center_3 = np.array([9, 8, 9, 10, 9])\n",
        "center_4 = np.array([7, 6, 7, 8, 7])\n",
        "\n",
        "# 1. Check normality for each group (Shapiro-Wilk test)\n",
        "print(\"Normality (Shapiro-Wilk):\")\n",
        "for name, group in zip(['Center 1', 'Center 2', 'Center 3', 'Center 4'], [center_1, center_2, center_3, center_4]):\n",
        "    stat, p = shapiro(group)\n",
        "    print(f\"{name}: p-value = {p:.4f}\")\n",
        "\n",
        "# 2. Check homogeneity of variances (Levene's test)\n",
        "stat, p = levene(center_1, center_2, center_3, center_4)\n",
        "print(f\"\\nLevene's test for equal variances: p-value = {p:.4f}\")\n",
        "\n",
        "# 3. Perform one-way ANOVA, kruskal if assumptions of anova are not met\n",
        "f_stat, p_value = f_oneway(center_1, center_2, center_3, center_4)\n",
        "print(f\"\\nANOVA: F-statistic = {f_stat:.2f}, p-value = {p_value:.4f}\")"
      ],
      "metadata": {
        "id": "0miN2ASBFbcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** If the assumptions of ANOVA test are not met then you use **Kruskal Test**"
      ],
      "metadata": {
        "id": "oIeO97AMaFE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How to Interpret the results**\n",
        "\n",
        "1. If all Shapiro-Wilk p-values > 0.05: Groups are normally distributed.\n",
        "\n",
        "2. If Levene’s p-value > 0.05: Variances are equal (homogeneity holds).\n",
        "\n",
        "3. If ANOVA p-value < 0.05: At least one group mean is significantly different."
      ],
      "metadata": {
        "id": "d7eMx2UZF0O2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Chi-Squared Test**"
      ],
      "metadata": {
        "id": "A4m_7f-WrZfz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem Statement:**\n",
        "\n",
        "A marketing team at a software company wants to determine if there is a relationship between the type of advertising medium (online, print, television) and software purchases. They collect data from a sample of customers, noting the advertising medium each customer was exposed to and whether they purchased the software.\n",
        "\n",
        "**Hypotheses:**\n",
        "\n",
        "- Null Hypothesis ($H_0$): There is no association between the type of advertising medium and software purchases. The variables are independent.\n",
        "- Alternative Hypothesis ($H_1$): There is an association between the type of advertising medium and software purchases. The variables are not independent."
      ],
      "metadata": {
        "id": "eX5tK6jgrlXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Observed frequency data in a contingency table\n",
        "# Rows in the data array represent: Advertising Medium (Online, Print, Television)\n",
        "# Columns in the data array represent: Purchase (Yes, No)\n",
        "data = np.array([[30, 10],  # Online\n",
        "                 [20, 20],  # Print\n",
        "                 [50, 30]]) # Television\n",
        "\n",
        "# Perform Chi-Square Test of Independence\n",
        "chi2_stat, p_value, dof, expected = chi2_contingency(data)\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(f\"Chi-Square Statistic: {chi2_stat:.4f}, p-value: {p_value:.4f}\")\n",
        "    print(\"We have sufficient evidence to reject the null hypothesis.\")\n",
        "    print(\"There is a significant association between the advertising medium and software purchases.\")\n",
        "else:\n",
        "    print(f\"Chi-Square Statistic: {chi2_stat:.4f}, p-value: {p_value:.4f}\")\n",
        "    print(\"We do not have sufficient evidence to reject the null hypothesis.\")\n",
        "    print(\"There is no significant association between the advertising medium and software purchases.\")"
      ],
      "metadata": {
        "id": "mn9XUPE1F88F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "379ae1b7-1164-43c4-dd51-36d6cbe1520e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chi-Square Statistic: 5.3333, p-value: 0.0695\n",
            "We do not have sufficient evidence to reject the null hypothesis.\n",
            "There is no significant association between the advertising medium and software purchases.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem Statement 2:**\n",
        "A restaurant chain wants to determine if there is an association between the type of cuisine offered (Italian, Chinese, Mexican) and customer satisfaction levels (satisfied, neutral, dissatisfied). They conduct a survey among customers across several locations to collect this data.\n",
        "\n",
        "**Hypotheses:**\n",
        "- Null Hypothesis ($H_0$): There is no association between the type of cuisine and customer satisfaction levels. The variables are independent.\n",
        "- Alternative Hypothesis ($H_1$): There is an association between the type of cuisine and customer satisfaction levels. The variables are not independent."
      ],
      "metadata": {
        "id": "a8LbeP9-rszY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Observed frequency data in a contingency table\n",
        "# Rows: Type of Cuisine (Italian, Chinese, Mexican)\n",
        "# Columns: Customer Satisfaction (Satisfied, Neutral, Dissatisfied)\n",
        "data = np.array([[40, 30, 10],  # Italian\n",
        "                 [35, 25, 20],  # Chinese\n",
        "                 [25, 30, 15]]) # Mexican\n",
        "\n",
        "# Perform Chi-Square Test of Independence\n",
        "chi2_stat, p_value, dof, expected = chi2_contingency(data)\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(f\"Chi-Square Statistic: {chi2_stat:.4f}, p-value: {p_value:.4f}\")\n",
        "    print(\"We have sufficient evidence to reject the null hypothesis.\")\n",
        "    print(\"There is a significant association between the type of cuisine and customer satisfaction levels.\")\n",
        "else:\n",
        "    print(f\"Chi-Square Statistic: {chi2_stat:.4f}, p-value: {p_value:.4f}\")\n",
        "    print(\"We do not have sufficient evidence to reject the null hypothesis.\")\n",
        "    print(\"There is no significant association between the type of cuisine and customer satisfaction levels.\")"
      ],
      "metadata": {
        "id": "OzSRqBpjrv5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario 3: Banking Risk Management (Credit Default)**\n",
        "\n",
        "**Problem Statement:** A commercial bank is analyzing its loan portfolio. The Risk Management team wants to understand if a customer's Housing Status (Own, Mortgage, Rent) influences their Loan Default Status (Defaulted, Paid Off). If there is a strong dependency, housing status will be weighted more heavily in the bank's future credit scoring models.\n",
        "\n",
        "**Hypothesis Statements:**\n",
        "\n",
        "- **Null Hypothesis ($H_0$):** Loan Default status is independent of Housing Status.\n",
        "- **Alternative Hypothesis ($H_1$):** Loan Default status is dependent on Housing Status."
      ],
      "metadata": {
        "id": "Htcditz0Tl8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# 1. Create a Contingency Table directly\n",
        "# In many reports, you are given the summarized table directly rather than raw rows.\n",
        "# Rows: Housing Status (Mortgage, Own, Rent)\n",
        "# Columns: Loan Status (Defaulted, Paid Off)\n",
        "\n",
        "data = [\n",
        "    [45, 350],  # Mortgage: 45 defaults, 350 paid off\n",
        "    [15, 200],  # Own: 15 defaults, 200 paid off\n",
        "    [60, 280]   # Rent: 60 defaults, 280 paid off\n",
        "]\n",
        "\n",
        "# Labels for clarity (not strictly needed for calculation but good for display)\n",
        "rows = ['Mortgage', 'Own', 'Rent']\n",
        "cols = ['Defaulted', 'Paid Off']\n",
        "contingency_table = pd.DataFrame(data, index=rows, columns=cols)\n",
        "\n",
        "print(\"--- Loan Portfolio Contingency Table ---\")\n",
        "print(contingency_table)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 2. Perform Chi-Squared Test\n",
        "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "# 3. Interpret Results\n",
        "alpha = 0.05\n",
        "print(f\"Chi2 Statistic: {chi2:.4f}\")\n",
        "print(f\"P-Value: {p:.4f}\")\n",
        "print(f\"Degrees of Freedom: {dof}\")\n",
        "\n",
        "if p < alpha:\n",
        "    print(\"Reject Null Hypothesis: Housing Status impacts Default Risk.\")\n",
        "else:\n",
        "    print(\"Fail to Reject Null Hypothesis: Housing Status has no significant effect on Default Risk.\")\n",
        "\n",
        "# Optional: View Expected Frequencies to check assumptions\n",
        "# (Chi-Square assumes expected frequency > 5 in each cell)\n",
        "print(\"\\nExpected Frequencies:\\n\", expected)"
      ],
      "metadata": {
        "id": "aUs80GrzO472"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T5_WAPLxThTc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}